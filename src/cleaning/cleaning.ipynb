{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Import required packages and libraries for data exploration\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Set up file path and data handling objects\n",
    "'''\n",
    "PATH = \"../data/reviews.csv\"\n",
    "data = pd.read_csv(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>568454.000000</td>\n",
       "      <td>568454.000000</td>\n",
       "      <td>568454.00000</td>\n",
       "      <td>568454.000000</td>\n",
       "      <td>5.684540e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>284227.500000</td>\n",
       "      <td>1.743817</td>\n",
       "      <td>2.22881</td>\n",
       "      <td>4.183199</td>\n",
       "      <td>1.296257e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>164098.679298</td>\n",
       "      <td>7.636513</td>\n",
       "      <td>8.28974</td>\n",
       "      <td>1.310436</td>\n",
       "      <td>4.804331e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.393408e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>142114.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.271290e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>284227.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.311120e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>426340.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.332720e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>568454.000000</td>\n",
       "      <td>866.000000</td>\n",
       "      <td>923.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.351210e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Id  HelpfulnessNumerator  HelpfulnessDenominator  \\\n",
       "count  568454.000000         568454.000000            568454.00000   \n",
       "mean   284227.500000              1.743817                 2.22881   \n",
       "std    164098.679298              7.636513                 8.28974   \n",
       "min         1.000000              0.000000                 0.00000   \n",
       "25%    142114.250000              0.000000                 0.00000   \n",
       "50%    284227.500000              0.000000                 1.00000   \n",
       "75%    426340.750000              2.000000                 2.00000   \n",
       "max    568454.000000            866.000000               923.00000   \n",
       "\n",
       "               Score          Time  \n",
       "count  568454.000000  5.684540e+05  \n",
       "mean        4.183199  1.296257e+09  \n",
       "std         1.310436  4.804331e+07  \n",
       "min         1.000000  9.393408e+08  \n",
       "25%         4.000000  1.271290e+09  \n",
       "50%         5.000000  1.311120e+09  \n",
       "75%         5.000000  1.332720e+09  \n",
       "max         5.000000  1.351210e+09  "
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Sensitivity\n",
    "Convert the input features in the raw dataset into a case insensitive format (all lowercase/uppercase) to reduce the amount of distinct words in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove null values from tokenizer strings\n",
    "data[\"Summary\"] = data[\"Summary\"].fillna(\"\")\n",
    "data[\"Text\"] = data[\"Text\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>good quality dog food</td>\n",
       "      <td>i have bought several of the vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>not as advertised</td>\n",
       "      <td>product arrived labeled as jumbo salted peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"delight\" says it all</td>\n",
       "      <td>this is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>cough medicine</td>\n",
       "      <td>if you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>great taffy</td>\n",
       "      <td>great taffy at a great price.  there was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  good quality dog food  i have bought several of the vitality canned d...  \n",
       "1      not as advertised  product arrived labeled as jumbo salted peanut...  \n",
       "2  \"delight\" says it all  this is a confection that has been around a fe...  \n",
       "3         cough medicine  if you are looking for the secret ingredient i...  \n",
       "4            great taffy  great taffy at a great price.  there was a wid...  "
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert all words to lowercase to reduce the number of unique features\n",
    "data[\"Summary\"] = data[\"Summary\"].str.lower()\n",
    "data[\"Text\"] = data[\"Text\"].str.lower()\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punctuation Handling\n",
    "Some words that contain punctuation can be recorded as separate features without punctuation handling (e.g., \"Steve's pizza is great!\" and \"Steve makes great pizza!\").\n",
    "\n",
    "| is | great | great! | makes | pizza | pizza! | Steve | Steve's |\n",
    "|----|-------|--------|-------|-------|--------|-------|---------|\n",
    "|1   | 1     | 1      | 1     | 1     | 1      | 1     | 1       |\n",
    "\n",
    "We want to remove uncessesary punctuation so that we don't have duplicates of effectively the same word.\n",
    "| is | great | makes | pizza | Steve |\n",
    "|----|-------|-------|-------|-------|\n",
    "| 1  | 2     | 1     | 2     | 2     |\n",
    "\n",
    "Doing this prevents our model from interpreting duplicate words as two separate features and reduces the number of dimensions our model has to process (increasing efficiency)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"(?u)\\b\\w\\w+\\b\"\n",
    "tokenizer = lambda string : \" \".join(re.findall(pattern=pattern, string=string))\n",
    "\n",
    "data[\"Summary\"] = data[\"Summary\"].apply(tokenizer)\n",
    "data[\"Text\"] = data[\"Text\"].apply(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Filler Words\n",
    "Some words like \"I\", \"the\", \"a\", etc. don't impact the sentiment of the text content. Remove these words from all review content so there is less redundant features for the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NLTK stopwords...\n",
      "\n",
      "Sample of English stopwords:\n",
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an']\n",
      "Removing stop words from Summary...\n",
      "Removing stop words from Text...\n",
      "\n",
      "Sample of processed Summary:\n",
      "0    good quality dog food\n",
      "1               advertised\n",
      "2             delight says\n",
      "3           cough medicine\n",
      "4              great taffy\n",
      "Name: Summary, dtype: object\n",
      "\n",
      "Sample of processed Text:\n",
      "0    bought several vitality canned dog food produc...\n",
      "1    product arrived labeled jumbo salted peanuts p...\n",
      "2    confection around centuries light pillowy citr...\n",
      "3    looking secret ingredient robitussin believe f...\n",
      "4    great taffy great price wide assortment yummy ...\n",
      "Name: Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords    \n",
    "\n",
    "print(\"Downloading NLTK stopwords...\")\n",
    "nltk.download('stopwords', quiet=True)\n",
    "    \n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Print sample of stopwords\n",
    "print(\"\\nSample of English stopwords:\")\n",
    "print(sorted(list(stop_words))[:10])  # Print first 10 stopwords\n",
    "\n",
    "def remove_stopwords_from_text(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    words = text.lower().split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Process both columns\n",
    "print(\"Removing stop words from Summary...\")\n",
    "data['Summary'] = data['Summary'].apply(remove_stopwords_from_text)\n",
    "\n",
    "print(\"Removing stop words from Text...\")\n",
    "data['Text'] = data['Text'].apply(remove_stopwords_from_text)\n",
    "\n",
    "# Print samples for verification\n",
    "print(\"\\nSample of processed Summary:\")\n",
    "print(data['Summary'].head())\n",
    "print(\"\\nSample of processed Text:\")\n",
    "print(data['Text'].head())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Irrelevant Data Points\n",
    "The first stage of data cleaning is to identify and remove data points that aren't related to our task. In \"Amazon Fine Food Reviews\", we have many different product reviews including: pet food, medicine, microwavable food, fine foods, etc.\n",
    "- Is this category of food or type of review relevant to our task?\n",
    "- Would removing this type of review from the data improve the accuracy of our model?\n",
    "- If we remove this type of review, how will it effect our training process (would there be too little data remaining?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_aspects = {\n",
    "    \"pet_species\":[\n",
    "        \"dog\",\"cat\",\"puppy\",\"kitten\",\"fish\",\"hamster\",\"rabbit\",\"guinea pig\",\"bird\",\"parrot\",\"turtle\",\n",
    "        \"lizard\", \"snake\", \"ferret\", \"gerbil\", \"chinchilla\", \"mouse\", \"rat\", \"iguana\", \"gecko\",\n",
    "        \"dogs\",\"cats\",\"puppys\",\"kittens\",\"fishs\",\"hamsters\",\"rabbits\",\"guinea pigs\",\"birds\",\"parrots\",\"turtles\",\n",
    "        \"lizards\", \"snakes\", \"ferrets\", \"gerbils\", \"chinchillas\", \"mouses\", \"rats\", \"iguanas\", \"geckos\"\n",
    "    ],\n",
    "    \"pet_food_brands\":[\n",
    "        \"purina\", \"pedigre\", \"iams\", \"blue buffalo\", \"hill science diet\", \"royal canin\", \"fancy feast\", \"friskies\",\n",
    "        \"cesar\", \"meow mix\", \"nutro\", \"wellness\", \"orijen\", \"acana\", \"greenies\", \"temptations\", \"whiskas\"\n",
    "    ],\n",
    "    \"digestive\": [\n",
    "        \"nausea\", \"vomiting\", \"diarrhea\", \"constipation\", \"bloating\",\n",
    "        \"stomach ache\", \"indigestion\", \"heartburn\", \"cramps\", \"gas\"\n",
    "    ],\n",
    "    \"neurological\": [\n",
    "        \"headache\", \"migraine\", \"dizziness\", \"fatigue\", \"insomnia\",\n",
    "        \"brain fog\", \"numbness\", \"tingling\", \"vertigo\"\n",
    "    ],\n",
    "    \"respiratory\": [\n",
    "        \"cough\", \"shortness of breath\", \"wheezing\", \"congestion\",\n",
    "        \"runny nose\", \"sore throat\", \"sneezing\"\n",
    "    ],\n",
    "    \"skin\": [\n",
    "        \"rash\", \"itching\", \"hives\", \"acne\", \"eczema\", \"redness\",\n",
    "        \"dry skin\", \"swelling\"\n",
    "    ],\n",
    "    \"pain\": [\n",
    "        \"pain\", \"ache\", \"soreness\", \"stiffness\", \"joint pain\",\n",
    "        \"back pain\", \"chest pain\", \"muscle pain\"\n",
    "    ],\n",
    "    \"psychological\": [\n",
    "        \"anxiety\", \"depression\", \"irritability\", \"mood swings\",\n",
    "        \"panic attacks\", \"restlessness\"\n",
    "    ],\n",
    "    \"general\": [\n",
    "        \"fever\", \"chills\", \"sweating\", \"weakness\", \"loss of appetite\",\n",
    "        \"weight loss\", \"weight gain\"\n",
    "    ],\n",
    "    \"allergic\": [\n",
    "        \"allergy\", \"anaphylaxis\", \"sensitivity\", \"intolerance\",\n",
    "        \"swelling of the lips\", \"swelling of the throat\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_prod(value, dataframe, series):\n",
    "    products = set()\n",
    "\n",
    "    for i, string in enumerate(series):\n",
    "        if re.search(pattern=f\"{value} \", string=string):\n",
    "            products.add(dataframe.iloc[i][\"ProductId\"])\n",
    "    return products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in non_aspects.keys():\n",
    "    for value in non_aspects[key]:\n",
    "        sum_id = search_prod(value=value, dataframe=data, series=data[\"Summary\"])\n",
    "        txt_id = search_prod(value=value, dataframe=data, series=data[\"Text\"])\n",
    "        prod_id = sum_id.union(txt_id)\n",
    "        \n",
    "        data = data[~data[\"ProductId\"].isin(prod_id)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>201853.000000</td>\n",
       "      <td>201853.000000</td>\n",
       "      <td>201853.000000</td>\n",
       "      <td>201853.000000</td>\n",
       "      <td>2.018530e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>285589.447806</td>\n",
       "      <td>1.472839</td>\n",
       "      <td>1.883643</td>\n",
       "      <td>4.211253</td>\n",
       "      <td>1.296484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>164068.765008</td>\n",
       "      <td>4.093552</td>\n",
       "      <td>4.709997</td>\n",
       "      <td>1.311492</td>\n",
       "      <td>4.942911e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.617184e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>142410.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.269994e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>283227.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.312934e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>428757.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.334016e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>568454.000000</td>\n",
       "      <td>580.000000</td>\n",
       "      <td>593.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.351210e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Id  HelpfulnessNumerator  HelpfulnessDenominator  \\\n",
       "count  201853.000000         201853.000000           201853.000000   \n",
       "mean   285589.447806              1.472839                1.883643   \n",
       "std    164068.765008              4.093552                4.709997   \n",
       "min         2.000000              0.000000                0.000000   \n",
       "25%    142410.000000              0.000000                0.000000   \n",
       "50%    283227.000000              0.000000                1.000000   \n",
       "75%    428757.000000              2.000000                2.000000   \n",
       "max    568454.000000            580.000000              593.000000   \n",
       "\n",
       "               Score          Time  \n",
       "count  201853.000000  2.018530e+05  \n",
       "mean        4.211253  1.296484e+09  \n",
       "std         1.311492  4.942911e+07  \n",
       "min         1.000000  9.617184e+08  \n",
       "25%         4.000000  1.269994e+09  \n",
       "50%         5.000000  1.312934e+09  \n",
       "75%         5.000000  1.334016e+09  \n",
       "max         5.000000  1.351210e+09  "
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>not as advertised</td>\n",
       "      <td>product arrived labeled as jumbo salted peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>delight says it all</td>\n",
       "      <td>this is confection that has been around few ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>great taffy</td>\n",
       "      <td>great taffy at great price there was wide asso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>ADT0SRK1MGOEU</td>\n",
       "      <td>Twoapennything</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1342051200</td>\n",
       "      <td>nice taffy</td>\n",
       "      <td>got wild hair for taffy and ordered this five ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1SP2KVKFXXRU1</td>\n",
       "      <td>David C. Sullivan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1340150400</td>\n",
       "      <td>great just as good as the expensive brands</td>\n",
       "      <td>this saltwater taffy had great flavors and was...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "5   6  B006K2ZZ7K   ADT0SRK1MGOEU                   Twoapennything   \n",
       "6   7  B006K2ZZ7K  A1SP2KVKFXXRU1                David C. Sullivan   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "4                     0                       0      5  1350777600   \n",
       "5                     0                       0      4  1342051200   \n",
       "6                     0                       0      5  1340150400   \n",
       "\n",
       "                                      Summary  \\\n",
       "1                           not as advertised   \n",
       "2                         delight says it all   \n",
       "4                                 great taffy   \n",
       "5                                  nice taffy   \n",
       "6  great just as good as the expensive brands   \n",
       "\n",
       "                                                Text  \n",
       "1  product arrived labeled as jumbo salted peanut...  \n",
       "2  this is confection that has been around few ce...  \n",
       "4  great taffy at great price there was wide asso...  \n",
       "5  got wild hair for taffy and ordered this five ...  \n",
       "6  this saltwater taffy had great flavors and was...  "
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Uncecessary Columns\n",
    "- What columns are necessary for our model? \n",
    "- Is there anything that needs to be removed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only include features that can be plotted in correlation matrix\n",
    "# String features cannot be intepreted in correlation matrix\n",
    "numeric_data = data.drop(columns=[\"ProductId\", \"UserId\", \"ProfileName\", \"Summary\", \"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Text\"] = data[\"Summary\"].fillna(\"\") + \" \" + data[\"Text\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As seen in the data exploration stage, most numerical features excluding \n",
    "# the newly created \"Helpfulness\" were not indicative of Score\n",
    "data = data.drop(columns=[\n",
    "    \"Id\",\n",
    "    \"UserId\", \n",
    "    \"ProfileName\", \n",
    "    \"HelpfulnessNumerator\", \n",
    "    \"HelpfulnessDenominator\",\n",
    "    \"Time\",\n",
    "    \"Summary\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>1</td>\n",
       "      <td>product arrived labeled as jumbo salted peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>4</td>\n",
       "      <td>this is confection that has been around few ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>5</td>\n",
       "      <td>great taffy at great price there was wide asso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>4</td>\n",
       "      <td>got wild hair for taffy and ordered this five ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>5</td>\n",
       "      <td>this saltwater taffy had great flavors and was...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ProductId  Score                                               Text\n",
       "1  B00813GRG4      1  product arrived labeled as jumbo salted peanut...\n",
       "2  B000LQOCH0      4  this is confection that has been around few ce...\n",
       "4  B006K2ZZ7K      5  great taffy at great price there was wide asso...\n",
       "5  B006K2ZZ7K      4  got wild hair for taffy and ordered this five ...\n",
       "6  B006K2ZZ7K      5  this saltwater taffy had great flavors and was..."
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Columns to Numerical\n",
    "For the more complex columns we will be doing word embedding. However, features such as 'ProductId' can be converted into numerical form so the model has an easier time interpreting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"ProductId\"] = pd.factorize(data[\"ProductId\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>product arrived labeled as jumbo salted peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>this is confection that has been around few ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>great taffy at great price there was wide asso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>got wild hair for taffy and ordered this five ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>this saltwater taffy had great flavors and was...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProductId  Score                                               Text\n",
       "1          0      1  product arrived labeled as jumbo salted peanut...\n",
       "2          1      4  this is confection that has been around few ce...\n",
       "4          2      5  great taffy at great price there was wide asso...\n",
       "5          2      4  got wild hair for taffy and ordered this five ...\n",
       "6          2      5  this saltwater taffy had great flavors and was..."
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Split\n",
    "In this section we need to split the dataset into single entity and multiple entity data points. This step is necessary because the framework for our model requires that single entity data points are handled by **model A** and multiple entity data points are handled by **model B**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Cyrus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def is_valid_noun(word):\n",
    "    doc = nlp(word)\n",
    "    is_noun = doc[0].pos_ in [\"NOUN\", \"PROPN\"]\n",
    "    in_wordnet = any(ss.pos() == 'n' for ss in wn.synsets(word))\n",
    "    return is_noun and in_wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(data.iloc[200][\"Text\"])\n",
    "tagged = nltk.pos_tag(tokens=tokens)\n",
    "entities = nltk.chunk.ne_chunk(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"120px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px\" version=\"1.1\" viewBox=\"0,0,1608.0,120.0\" width=\"1608px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"2.48756%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">the</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"1.24378%\" y1=\"20px\" y2=\"48px\" /><svg width=\"3.48259%\" x=\"2.48756%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">price</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"4.22886%\" y1=\"20px\" y2=\"48px\" /><svg width=\"1.99005%\" x=\"5.97015%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">on</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"6.96517%\" y1=\"20px\" y2=\"48px\" /><svg width=\"2.98507%\" x=\"7.9602%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">this</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"9.45274%\" y1=\"20px\" y2=\"48px\" /><svg width=\"4.47761%\" x=\"10.9453%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">product</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"13.1841%\" y1=\"20px\" y2=\"48px\" /><svg width=\"5.47264%\" x=\"15.4229%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">certainly</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">RB</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"18.1592%\" y1=\"20px\" y2=\"48px\" /><svg width=\"3.9801%\" x=\"20.8955%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">raises</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBZ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"22.8856%\" y1=\"20px\" y2=\"48px\" /><svg width=\"2.98507%\" x=\"24.8756%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">my</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">PRP$</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"26.3682%\" y1=\"20px\" y2=\"48px\" /><svg width=\"5.47264%\" x=\"27.8607%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">attention</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"30.597%\" y1=\"20px\" y2=\"48px\" /><svg width=\"1.99005%\" x=\"33.3333%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">on</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"34.3284%\" y1=\"20px\" y2=\"48px\" /><svg width=\"5.97015%\" x=\"35.3234%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">compairing</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBG</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"38.3085%\" y1=\"20px\" y2=\"48px\" /><svg width=\"3.9801%\" x=\"41.2935%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">amazon</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"43.2836%\" y1=\"20px\" y2=\"48px\" /><svg width=\"3.48259%\" x=\"45.2736%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">price</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"47.0149%\" y1=\"20px\" y2=\"48px\" /><svg width=\"2.98507%\" x=\"48.7562%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">with</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50.2488%\" y1=\"20px\" y2=\"48px\" /><svg width=\"2.48756%\" x=\"51.7413%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">the</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"52.9851%\" y1=\"20px\" y2=\"48px\" /><svg width=\"3.48259%\" x=\"54.2289%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">local</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"55.9701%\" y1=\"20px\" y2=\"48px\" /><svg width=\"3.9801%\" x=\"57.7114%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">stores</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNS</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"59.7015%\" y1=\"20px\" y2=\"48px\" /><svg width=\"2.48756%\" x=\"61.6915%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">can</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">MD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"62.9353%\" y1=\"20px\" y2=\"48px\" /><svg width=\"2.48756%\" x=\"64.1791%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">get</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VB</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"65.4229%\" y1=\"20px\" y2=\"48px\" /><svg width=\"2.48756%\" x=\"66.6667%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">can</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">MD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"67.9104%\" y1=\"20px\" y2=\"48px\" /><svg width=\"1.99005%\" x=\"69.1542%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">of</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"70.1493%\" y1=\"20px\" y2=\"48px\" /><svg width=\"2.98507%\" x=\"71.1443%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">this</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"72.6368%\" y1=\"20px\" y2=\"48px\" /><svg width=\"3.48259%\" x=\"74.1294%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">rotel</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"75.8706%\" y1=\"20px\" y2=\"48px\" /><svg width=\"1.99005%\" x=\"77.6119%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">at</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"78.607%\" y1=\"20px\" y2=\"48px\" /><svg width=\"2.98507%\" x=\"79.602%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">my</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">PRP$</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"81.0945%\" y1=\"20px\" y2=\"48px\" /><svg width=\"3.48259%\" x=\"82.5871%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">local</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"84.3284%\" y1=\"20px\" y2=\"48px\" /><svg width=\"3.9801%\" x=\"86.0697%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">kroger</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"88.0597%\" y1=\"20px\" y2=\"48px\" /><svg width=\"2.48756%\" x=\"90.0498%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">for</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"91.2935%\" y1=\"20px\" y2=\"48px\" /><svg width=\"7.46269%\" x=\"92.5373%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">dissapointing</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBG</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"96.2687%\" y1=\"20px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('S', [('the', 'DT'), ('price', 'NN'), ('on', 'IN'), ('this', 'DT'), ('product', 'NN'), ('certainly', 'RB'), ('raises', 'VBZ'), ('my', 'PRP$'), ('attention', 'NN'), ('on', 'IN'), ('compairing', 'VBG'), ('amazon', 'JJ'), ('price', 'NN'), ('with', 'IN'), ('the', 'DT'), ('local', 'JJ'), ('stores', 'NNS'), ('can', 'MD'), ('get', 'VB'), ('can', 'MD'), ('of', 'IN'), ('this', 'DT'), ('rotel', 'NN'), ('at', 'IN'), ('my', 'PRP$'), ('local', 'JJ'), ('kroger', 'NN'), ('for', 'IN'), ('dissapointing', 'VBG')])"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspects     = []\n",
    "sentiments  = []\n",
    "\n",
    "aspect_tags     = {\"NN\"}\n",
    "sentiment_tags  = {\"JJ\", \"JJR\", \"JJS\", \"RBR\", \"RBS\"}\n",
    "\n",
    "for i, tag in enumerate(tagged):\n",
    "    if tag[1] in sentiment_tags:\n",
    "        sentiments.append(((tag[0]), i))\n",
    "    if tag[1] == \"VBN\":\n",
    "        for k in range(1, len(tag[0])):\n",
    "            if is_valid_noun(tag[0][:-k]):\n",
    "                aspects.append((tag[0][:-k], i))\n",
    "                break\n",
    "    elif tag[1] in aspect_tags:\n",
    "        aspects.append((tag[0], i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('price', 1), ('product', 4), ('attention', 8), ('price', 12), ('rotel', 22), ('kroger', 26)]\n",
      "[('amazon', 11), ('local', 15), ('local', 25)]\n"
     ]
    }
   ],
   "source": [
    "print(aspects)\n",
    "print(sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'product arrived labeled as jumbo salted peanuts the peanuts were actually small sized unsalted not sure if this was an error or if the vendor intended to represent the product as jumbo'"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0][\"Text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from scipy.sparse import lil_matrix\n",
    "from scipy.sparse import vstack\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH = \"Aspect Term Extraction and Polarity Classification.FAST_LCF_ATEPC.result.json\"\n",
    "\n",
    "# Open and load the JSON file\n",
    "with open(RESULTS_PATH, 'r') as file:\n",
    "    results = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_to_score = {\n",
    "    \"Negative\" : 1,\n",
    "    \"Neutral\"  : 2,\n",
    "    \"Positive\" : 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary of all unique aspect terms\n",
    "all_aspects = set()\n",
    "\n",
    "for result in results:\n",
    "    for aspect in result.get(\"aspect\", []):\n",
    "        all_aspects.add(aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign each aspect a column index\n",
    "aspect_names = sorted(all_aspects)\n",
    "aspect_vocab = {aspect: idx for idx, aspect in enumerate(aspect_names)}\n",
    "n_samples    = len(results)\n",
    "n_features   = len(aspect_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sparse matrix using LIL (good for row-wise construction)\n",
    "sentiment_matrix = lil_matrix((n_samples, n_features), dtype=np.float32)\n",
    "\n",
    "# Keep track of rows with one or fewer aspect counts\n",
    "nonzero_counts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the matrix\n",
    "for i, result in enumerate(results):\n",
    "    aspects     = result.get(\"aspect\", [])\n",
    "    sentiments  = result.get(\"sentiment\", [])\n",
    "    count       = 0\n",
    "    for aspect, sentiment in zip(aspects, sentiments):\n",
    "        col_idx = aspect_vocab.get(aspect)\n",
    "        if col_idx is not None:\n",
    "            sentiment_score = sentiment_to_score.get(sentiment, 0)\n",
    "            sentiment_matrix[i, col_idx] = sentiment_score\n",
    "            count += 1\n",
    "\n",
    "    nonzero_counts.append(count)\n",
    "\n",
    "# Convert to CSR for efficient arithmetic / storage\n",
    "sentiment_matrix = sentiment_matrix.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter indicies\n",
    "low_aspect_indicies     = [i for i, count in enumerate(nonzero_counts) if count <= 1]\n",
    "high_aspect_indicies    = [i for i, count in enumerate(nonzero_counts) if count > 1]\n",
    "\n",
    "# Create two separate matrices\n",
    "low_aspect_matrix   = sentiment_matrix[low_aspect_indicies]\n",
    "high_aspect_matrix  = sentiment_matrix[high_aspect_indicies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Let's say:\n",
    "    - \"sentiment_matrix\" is your sparse matrix (CSR format)\n",
    "    - \"data\" is your original DataFrame with columns like \"Score\", \"ProductID\", \"Helpfulness\"\n",
    "'''\n",
    "\n",
    "# Dense columns for inclusion into sparse matrix\n",
    "dense_features = [\"ProductId\", \"Helpfulness\", \"Score\"]\n",
    "\n",
    "# Get dense data for each split\n",
    "low_dense   = data.iloc[low_aspect_indicies][dense_features].values\n",
    "high_dense  = data.iloc[high_aspect_indicies][dense_features].values\n",
    "\n",
    "# Convert dense to sparse and stack\n",
    "low_combined    = hstack([csr_matrix(low_dense), low_aspect_matrix])\n",
    "high_combined   = hstack([csr_matrix(high_dense), high_aspect_matrix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = dense_features + aspect_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to External Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['multi_aspect.pkl']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save both matrix and column names\n",
    "joblib.dump({\n",
    "    \"matrix\": low_combined,\n",
    "    \"columns\": column_names\n",
    "}, \"single_aspect.pkl\")\n",
    "\n",
    "joblib.dump({\n",
    "    \"matrix\": high_combined,\n",
    "    \"columns\": column_names\n",
    "}, \"multi_aspect.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tfenv)",
   "language": "python",
   "name": "tfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
